{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470696f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a04c96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pass_at_k(n, c, k):\n",
    "    if n - c < k: \n",
    "        return 1.0\n",
    "    return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01d0e0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'HumanEval/12',\n",
       " 'completion': {'warning': \"This model version is deprecated and a newer version 'gpt-4-0613' is available. Migrate before September 13 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
       "  'id': 'chatcmpl-7fZE9zW54uMA6uI0Xj2uKDjFaLScm',\n",
       "  'object': 'chat.completion',\n",
       "  'created': 1690141217,\n",
       "  'model': 'gpt-4-0314',\n",
       "  'choices': [{'index': 0,\n",
       "    'message': {'role': 'assistant',\n",
       "     'content': '    if not strings:\\n        return None\\n    longest_string = strings[0]\\n    for string in strings:\\n        if len(string) > len(longest_string):\\n            longest_string = string\\n    return longest_string'},\n",
       "    'finish_reason': 'stop'}],\n",
       "  'usage': {'prompt_tokens': 103,\n",
       "   'completion_tokens': 44,\n",
       "   'total_tokens': 147}},\n",
       " 'result': 'passed',\n",
       " 'passed': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#pars json\n",
    "with open('4.0-0314-temp0.6-samples.jsonl_results.jsonl', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "#data[0]\n",
    "data[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0c6abd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HumanEval/0': 9, 'HumanEval/1': 7, 'HumanEval/2': 6, 'HumanEval/3': 6, 'HumanEval/4': 10, 'HumanEval/5': 10, 'HumanEval/6': 10, 'HumanEval/7': 10, 'HumanEval/8': 10, 'HumanEval/9': 10, 'HumanEval/10': 2, 'HumanEval/11': 10, 'HumanEval/12': 10, 'HumanEval/13': 10, 'HumanEval/14': 10, 'HumanEval/15': 10, 'HumanEval/16': 8, 'HumanEval/17': 9, 'HumanEval/18': 10, 'HumanEval/19': 8, 'HumanEval/20': 10, 'HumanEval/21': 10, 'HumanEval/22': 9, 'HumanEval/23': 10, 'HumanEval/24': 9, 'HumanEval/25': 9, 'HumanEval/26': 9, 'HumanEval/27': 3, 'HumanEval/28': 10, 'HumanEval/29': 10, 'HumanEval/30': 10, 'HumanEval/31': 7, 'HumanEval/32': 4, 'HumanEval/33': 10, 'HumanEval/34': 10, 'HumanEval/35': 10, 'HumanEval/36': 3, 'HumanEval/37': 10, 'HumanEval/38': 10, 'HumanEval/39': 3, 'HumanEval/40': 9, 'HumanEval/41': 0, 'HumanEval/42': 10, 'HumanEval/43': 9, 'HumanEval/44': 9, 'HumanEval/45': 3, 'HumanEval/46': 10, 'HumanEval/47': 10, 'HumanEval/48': 10, 'HumanEval/49': 8, 'HumanEval/50': 1, 'HumanEval/51': 9, 'HumanEval/52': 9, 'HumanEval/53': 10, 'HumanEval/54': 9, 'HumanEval/55': 10, 'HumanEval/56': 5, 'HumanEval/57': 4, 'HumanEval/58': 10, 'HumanEval/59': 9, 'HumanEval/60': 10, 'HumanEval/61': 8, 'HumanEval/62': 7, 'HumanEval/63': 10, 'HumanEval/64': 8, 'HumanEval/65': 7, 'HumanEval/66': 10, 'HumanEval/67': 10, 'HumanEval/68': 10, 'HumanEval/69': 10, 'HumanEval/70': 10, 'HumanEval/71': 10, 'HumanEval/72': 10, 'HumanEval/73': 8, 'HumanEval/74': 3, 'HumanEval/75': 0, 'HumanEval/76': 9, 'HumanEval/77': 7, 'HumanEval/78': 10, 'HumanEval/79': 10, 'HumanEval/80': 5, 'HumanEval/81': 9, 'HumanEval/82': 10, 'HumanEval/83': 0, 'HumanEval/84': 0, 'HumanEval/85': 6, 'HumanEval/86': 10, 'HumanEval/87': 10, 'HumanEval/88': 8, 'HumanEval/89': 10, 'HumanEval/90': 10, 'HumanEval/91': 6, 'HumanEval/92': 10, 'HumanEval/93': 1, 'HumanEval/94': 10, 'HumanEval/95': 8, 'HumanEval/96': 10, 'HumanEval/97': 10, 'HumanEval/98': 9, 'HumanEval/99': 10, 'HumanEval/100': 8, 'HumanEval/101': 9, 'HumanEval/102': 6, 'HumanEval/103': 9, 'HumanEval/104': 10, 'HumanEval/105': 10, 'HumanEval/106': 7, 'HumanEval/107': 10, 'HumanEval/108': 0, 'HumanEval/109': 10, 'HumanEval/110': 10, 'HumanEval/111': 10, 'HumanEval/112': 10, 'HumanEval/113': 10, 'HumanEval/114': 10, 'HumanEval/115': 0, 'HumanEval/116': 10, 'HumanEval/117': 10, 'HumanEval/118': 4, 'HumanEval/119': 0, 'HumanEval/120': 0, 'HumanEval/121': 4, 'HumanEval/122': 9, 'HumanEval/123': 10, 'HumanEval/124': 10, 'HumanEval/125': 8, 'HumanEval/126': 9, 'HumanEval/127': 10, 'HumanEval/128': 8, 'HumanEval/129': 0, 'HumanEval/130': 6, 'HumanEval/131': 10, 'HumanEval/132': 0, 'HumanEval/133': 10, 'HumanEval/134': 6, 'HumanEval/135': 10, 'HumanEval/136': 10, 'HumanEval/137': 6, 'HumanEval/138': 7, 'HumanEval/139': 8, 'HumanEval/140': 1, 'HumanEval/141': 7, 'HumanEval/142': 9, 'HumanEval/143': 10, 'HumanEval/144': 9, 'HumanEval/145': 0, 'HumanEval/146': 10, 'HumanEval/147': 0, 'HumanEval/148': 10, 'HumanEval/149': 5, 'HumanEval/150': 10, 'HumanEval/151': 10, 'HumanEval/152': 10, 'HumanEval/153': 10, 'HumanEval/154': 10, 'HumanEval/155': 4, 'HumanEval/156': 9, 'HumanEval/157': 10, 'HumanEval/158': 10, 'HumanEval/159': 10, 'HumanEval/160': 2, 'HumanEval/161': 10, 'HumanEval/162': 10, 'HumanEval/163': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# getting # of correct sampels per prob\n",
    "\n",
    "correct_counts = {}\n",
    "for entry in data:\n",
    "    problem_id = entry[\"task_id\"]\n",
    "    is_correct = entry[\"passed\"]\n",
    "    if problem_id not in correct_counts:\n",
    "        correct_counts[problem_id] = 0\n",
    "    if is_correct:\n",
    "        correct_counts[problem_id] += 1\n",
    "\n",
    "print(correct_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2feb0964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#calc pass@10 for each problem, then taek teh average pass@10 over all 164 problems. this is what the expected value means.\n",
    "pass_at_10_values = []\n",
    "for problem, correct_count in correct_counts.items():\n",
    "    n_problem = 10\n",
    "    c_problem = correct_count\n",
    "    pass_at_10_problem = pass_at_k(n_problem, c_problem, 10)\n",
    "    pass_at_10_values.append(pass_at_10_problem)\n",
    "\n",
    "print(pass_at_10_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffcbff39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9207317073170732"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "average_pass_at_10 = sum(pass_at_10_values) / len(pass_at_10_values)\n",
    "average_pass_at_10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
